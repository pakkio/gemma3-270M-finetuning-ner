{
  "best_global_step": 200,
  "best_metric": 0.01937713846564293,
  "best_model_checkpoint": "outputs/gemma3-robust-training/checkpoint-200",
  "epoch": 3.6363636363636362,
  "eval_steps": 200,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 1.3314884901046753,
      "learning_rate": 0.00017272727272727275,
      "loss": 0.6803,
      "mean_token_accuracy": 0.8349028348922729,
      "num_tokens": 20225.0,
      "step": 20
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 1.274991512298584,
      "learning_rate": 0.00019918487514080865,
      "loss": 0.1419,
      "mean_token_accuracy": 0.9601858347654343,
      "num_tokens": 40246.0,
      "step": 40
    },
    {
      "epoch": 1.0909090909090908,
      "grad_norm": 0.45682382583618164,
      "learning_rate": 0.00019615832920842586,
      "loss": 0.0547,
      "mean_token_accuracy": 0.9886116907000542,
      "num_tokens": 59826.0,
      "step": 60
    },
    {
      "epoch": 1.4545454545454546,
      "grad_norm": 1.4072836637496948,
      "learning_rate": 0.00019096319953545185,
      "loss": 0.0508,
      "mean_token_accuracy": 0.9827678799629211,
      "num_tokens": 79828.0,
      "step": 80
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.8832389116287231,
      "learning_rate": 0.00018371664782625287,
      "loss": 0.0377,
      "mean_token_accuracy": 0.9892231181263924,
      "num_tokens": 99812.0,
      "step": 100
    },
    {
      "epoch": 2.1818181818181817,
      "grad_norm": 0.15157435834407806,
      "learning_rate": 0.00017458209990510527,
      "loss": 0.0256,
      "mean_token_accuracy": 0.9929523587226867,
      "num_tokens": 119530.0,
      "step": 120
    },
    {
      "epoch": 2.5454545454545454,
      "grad_norm": 0.2511071562767029,
      "learning_rate": 0.0001637655601011454,
      "loss": 0.0237,
      "mean_token_accuracy": 0.9926275506615638,
      "num_tokens": 139632.0,
      "step": 140
    },
    {
      "epoch": 2.909090909090909,
      "grad_norm": 1.2068958282470703,
      "learning_rate": 0.0001515109653935348,
      "loss": 0.017,
      "mean_token_accuracy": 0.9960693717002869,
      "num_tokens": 159648.0,
      "step": 160
    },
    {
      "epoch": 3.2727272727272725,
      "grad_norm": 0.10154467076063156,
      "learning_rate": 0.00013809468409117846,
      "loss": 0.0097,
      "mean_token_accuracy": 0.9967417329549789,
      "num_tokens": 179423.0,
      "step": 180
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 0.35517022013664246,
      "learning_rate": 0.00012381928311397806,
      "loss": 0.0093,
      "mean_token_accuracy": 0.9969663113355637,
      "num_tokens": 199405.0,
      "step": 200
    },
    {
      "epoch": 3.6363636363636362,
      "eval_loss": 0.01937713846564293,
      "eval_mean_token_accuracy": 0.993907927198613,
      "eval_num_tokens": 199405.0,
      "eval_runtime": 4.1789,
      "eval_samples_per_second": 22.255,
      "eval_steps_per_second": 11.247,
      "step": 200
    }
  ],
  "logging_steps": 20,
  "max_steps": 440,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 128898148984320.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
